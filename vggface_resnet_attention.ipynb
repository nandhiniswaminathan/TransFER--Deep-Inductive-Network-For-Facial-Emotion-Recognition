{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vggface resnet attention",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandhiniswaminathan/face-recognition/blob/master/vggface_resnet_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksYNPc_Le8T_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras\n",
        "!pip install keras_vggface\n",
        "!pip install pandas\n",
        "!pip install scikit_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmR1Fk0HkMEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00b3bf52-ee50-4a1a-a61b-993a316e18f9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys,os\n",
        "from skimage.transform import resize\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, Callback\n",
        "from keras import optimizers\n",
        "from google.colab import drive\n",
        "from keras.layers import Input\n",
        "from keras.layers import Input, Dense, Conv2D, BatchNormalization, RepeatVector, Multiply, Permute, Reshape,MaxPooling2D, Flatten, Dropout, InputLayer,Activation\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras import optimizers\n",
        "import keras\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrDaxiOOl3t6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder =  \"/content/drive/Colab Notebooks/\"\n",
        "\n",
        "img_height, img_width = 197, 197\n",
        "\n",
        "# Declaration of Parameters\n",
        "num_classes         = 7     \n",
        "epochs_top_layers   = 5\n",
        "epochs_all_layers   = 50\n",
        "batch_size          = 128\n",
        "input_shape=(img_height, img_width,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFL2q_FCmBd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e4cd465e-1f0e-448b-eab9-34374bc2e66d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqBMATBGmJf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "sys.path.insert(0, filepath)\n",
        "os.chdir(filepath)\n",
        "\n",
        "train_dir='train.csv'\n",
        "test_dir='test.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auXwdu5fmNIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wdata = pd.read_csv(train_dir)\n",
        "data=wdata.iloc[1:1000,]\n",
        "ddt=wdata.iloc[1001:1300,]\n",
        "gd=pd.read_csv(test_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EVue4M2mScD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92c60ba5-6166-4113-8a94-0cacd082e73b"
      },
      "source": [
        "print(gd.size)\n",
        "test=gd.iloc[0:1794,]\n",
        "#for better accuracy train on more data "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJiH_7pqkMLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9a10ace-5a3d-49ba-ec21-02f278369f31"
      },
      "source": [
        "base_model = VGGFace(\n",
        "    model       = 'resnet50',\n",
        "    include_top = False,\n",
        "    weights     = 'vggface',\n",
        "    input_shape = (img_height, img_width, 3))\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 1s 0us/step\n",
            "Model: \"vggface_resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 197, 197, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 99, 99, 64)   9408        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 99, 99, 64)   256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 99, 99, 64)   0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 49, 49, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 49, 49, 64)   4096        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 49, 49, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 49, 49, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 49, 49, 256)  16384       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 49, 49, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 49, 49, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 49, 49, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 49, 49, 64)   16384       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 49, 49, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 49, 49, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 49, 49, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 49, 49, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 49, 49, 64)   16384       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 49, 49, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 49, 49, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 49, 49, 64)   36864       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 49, 49, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 49, 49, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 49, 49, 256)  16384       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 49, 49, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 49, 49, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 49, 49, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 25, 25, 128)  32768       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 25, 25, 512)  131072      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 25, 25, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 25, 25, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 25, 25, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 25, 25, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 25, 25, 128)  65536       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 25, 25, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 25, 25, 128)  147456      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 25, 25, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 25, 25, 512)  65536       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 25, 25, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 25, 25, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 13, 13, 256)  131072      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 13, 13, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 13, 13, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 13, 13, 1024) 524288      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 13, 13, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 13, 13, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 13, 13, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 13, 13, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 13, 13, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 13, 13, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 13, 13, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 13, 13, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 13, 13, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 13, 13, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 13, 13, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 13, 13, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 13, 13, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 13, 13, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 13, 13, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 13, 13, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 13, 13, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 13, 13, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 13, 13, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 13, 13, 256)  262144      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 13, 13, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 13, 13, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 13, 13, 256)  589824      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 13, 13, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 13, 13, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 13, 13, 1024) 262144      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 13, 13, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 13, 13, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 13, 13, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 23,561,152\n",
            "Trainable params: 23,508,032\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pTFcPiOmVWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation = 'relu')(x)\n",
        "predictions = Dense(num_classes, activation = 'softmax')(x)\n",
        "\n",
        "# The model to be trained\n",
        "model = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wzqxM5xswcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = Input(shape=(197,197,3))\n",
        "o1 = Conv2D(32, kernel_size=(3, 3), activation=None)(i)\n",
        "o2 = BatchNormalization()(o1)\n",
        "o3 = Conv2D(64, kernel_size=(3,3),activation=None)(o2)\n",
        "o4 = BatchNormalization()(o3)\n",
        "o1 = Conv2D(128,kernel_size=(3,3),activation=None)(o1)\n",
        "o4 = Activation('relu')(o4)\n",
        "o4 = Dropout(0.25)(o4)\n",
        "o5 = keras.layers.add([o1,o3,o4])\n",
        "o5 = BatchNormalization()(o5)\n",
        "o5 = Activation('relu')(o5)\n",
        "\n",
        "attn = Dense(1, activation='tanh')(o5)\n",
        "attn = Flatten()(attn)\n",
        "attn = Activation('softmax')(attn)\n",
        "attn = RepeatVector(64)(attn)\n",
        "attn = Permute([2, 1])(attn)\n",
        "\n",
        "o5 = Reshape((193,64))(o5)\n",
        "o6 = Multiply()([o5, attn])\n",
        "o6 = Flatten()(o6)\n",
        "o6 = Dense(12, activation=None)(o6)\n",
        "o6 = BatchNormalization()(o6)\n",
        "o6 = Activation('relu')(o6)\n",
        "o6 = Dropout(0.5)(o6)\n",
        "o6 = Dense(7,activation='softmax')(o6)\n",
        "\n",
        "\n",
        "model_finetunedd = Model(inputs=i,outputs=o6)\n",
        "print(\"model\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nf4tLaEt009",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "97c6208d-252e-47e4-b89e-cdd781be0c53"
      },
      "source": [
        "model_finetuned = Sequential()\n",
        "model_finetuned.add(model)\n",
        "model_finetuned.add(Dense(32, activation='relu', input_dim=input_shape))\n",
        "model_finetuned.add(Dropout(0.25))\n",
        "model_finetuned.add(Dense(64, activation='relu'))\n",
        "model_finetuned.add(Dropout(0.5))\n",
        "model_finetuned.add(Dense(7, activation='sigmoid'))\n",
        "\n",
        "model_finetuned.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
        "              metrics=['accuracy'])\n",
        "model_finetuned.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_1 (Model)              (None, 7)                 25666503  \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                256       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 7)                 455       \n",
            "=================================================================\n",
            "Total params: 25,669,326\n",
            "Trainable params: 25,616,206\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbwBqbYmvnKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_input(x):\n",
        "    x -= 128.8006 # np.mean(train_dataset)\n",
        "    return x\n",
        "\n",
        "# Function to read the data from the csv file, increase the size of the images and return the images and their labels\n",
        "def get_data(data):\n",
        "    pixels = data['pixels'].tolist()\n",
        "    images = np.empty((len(data), 48,48, 3))\n",
        "    i = 0\n",
        "\n",
        "    for pixel_sequence in pixels:\n",
        "        single_image = [float(pixel) for pixel in pixel_sequence.split(' ')]  # Extraction of each single\n",
        "        single_image = np.asarray(single_image).reshape(48, 48) # Dimension: 48x48\n",
        "        single_image = resize(single_image, (48,48), order = 3, mode = 'constant') # Dimension: 139x139x3 (Bicubic)\n",
        "        ret = np.empty((48,48, 3))  \n",
        "        ret[:, :, 0] = single_image\n",
        "        ret[:, :, 1] = single_image\n",
        "        ret[:, :, 2] = single_image\n",
        "        images[i, :, :, :] = ret\n",
        "        i += 1\n",
        "    \n",
        "    images = preprocess_input(images)\n",
        "    labels = to_categorical(data['emotion'])\n",
        "\n",
        "    return images, labels    \n",
        "\n",
        "# Data preparation\n",
        "train_data_x, train_data_y  = get_data(data)\n",
        "val_data  = get_data(ddt)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ICG8wgOvrr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range  = 10,\n",
        "    shear_range     = 10, # 10 degrees\n",
        "    zoom_range      = 0.1,\n",
        "    fill_mode       = 'reflect',\n",
        "    horizontal_flip = True)\n",
        "\n",
        "# Takes numpy data & label arrays, and generates batches of augmented/normalized data. Yields batcfillhes indefinitely, in an infinite loop\n",
        "    # x:            Data. Should have rank 4. In case of grayscale data, the channels axis should have value 1, and in case of RGB data, \n",
        "    #               it should have value 3\n",
        "    # y:            Labels\n",
        "    # batch_size:   Int (default: 32)\n",
        "train_generator = train_datagen.flow(\n",
        "    train_data_x,\n",
        "    train_data_y,\n",
        "    batch_size  = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPwyMgYNzpLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_finetuned.compile(\n",
        "    optimizer   = Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0), \n",
        "    loss        = 'categorical_crossentropy', \n",
        "    metrics     = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K4wohjFz1Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_finetuned.fit_generator(\n",
        "    generator           = train_generator,\n",
        "    steps_per_epoch     = len(train_data_x) // batch_size,  # samples_per_epoch / batch_size\n",
        "    epochs              = 1,                            \n",
        "    validation_data     = val_data) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDpJKhzD2aIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fine-tuning the model by unfreezing the convolution layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WddAErIW2VVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "model.compile(\n",
        "    optimizer   = optimizers.SGD(lr = 1e-4, momentum = 0.9, decay = 0.0, nesterov = True),\n",
        "    loss        = 'categorical_crossentropy', \n",
        "    metrics     = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVchiNmY2NCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard_all_layers = TensorBoard(\n",
        "    log_dir         = folder + '/logs_all_layers',\n",
        "    histogram_freq  = 0,\n",
        "    write_graph     = True,\n",
        "    write_grads     = False,\n",
        "    write_images    = True)\n",
        "#save progress in drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY9exifN2NKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch):\n",
        "    updated_lr = K.get_value(model.optimizer.lr) * 0.5\n",
        "    if (epoch % 3 == 0) and (epoch != 0):\n",
        "        K.set_value(model.optimizer.lr, updated_lr)\n",
        "        print(K.get_value(model.optimizer.lr))\n",
        "    return K.get_value(model.optimizer.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB3Jz3Da2wBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Learning rate scheduler\n",
        "    # schedule: a function that takes an epoch index as input (integer, indexed from 0) and current learning\n",
        "    #ate and returns a new learning rate as output (float)\n",
        "reduce_lr = LearningRateScheduler(scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCThbFUT2A4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduce_lr_plateau = ReduceLROnPlateau(\n",
        "\tmonitor \t= 'val_loss',\n",
        "\tfactor\t\t= 0.5,\n",
        "\tpatience\t= 3,\n",
        "\tmode \t\t= 'auto',\n",
        "\tmin_lr\t\t= 1e-8)\n",
        "\n",
        "# Stop training when a monitored quantity has stopped improving\n",
        "\t# monitor:\t\tQuantity to be monitored\n",
        "\t# patience:\t\tNumber of epochs with no improvement after which training will be stopped\n",
        "\t# mode: \t\tOne of {auto, min, max}\n",
        "early_stop = EarlyStopping(\n",
        "\tmonitor \t= 'val_loss',\n",
        "\tpatience \t= 10,\n",
        "\tmode \t\t= 'auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvH8lyGG1_x_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f1cb0c8b-2732-4d08-ad46-86dba505d765"
      },
      "source": [
        "model.fit_generator(\n",
        "    generator           = train_generator,\n",
        "    steps_per_epoch     = len(train_data_x) // batch_size,  # samples_per_epoch / batch_size \n",
        "    epochs              = 1,                        \n",
        "    validation_data     = val_data,\n",
        "    callbacks           = [reduce_lr, reduce_lr_plateau, early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "7/7 [==============================] - 260s 37s/step - loss: 24.7682 - accuracy: 0.1240 - val_loss: 859830.4114 - val_accuracy: 0.1639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1874a1ba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_cFu-l3137x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate(np.array(val_data), np.array(m), batch_size=batch_size)\n",
        "print(\"Loss: \" + str(scores[0]))\n",
        "print(\"Accuracy: \" + str(scores[1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}